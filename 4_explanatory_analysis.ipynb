{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUANTUMBLACK CONFIDENTIAL\n",
    "\n",
    "\n",
    "##### Copyright (c) 2019 - present QuantumBlack Visual Analytics Ltd. All\n",
    "##### Rights Reserved.\n",
    "\n",
    "NOTICE: All information contained herein is, and remains the property of\n",
    "QuantumBlack Visual Analytics Ltd. and its suppliers, if any. The\n",
    "intellectual and technical concepts contained herein are proprietary to\n",
    "QuantumBlack Visual Analytics Ltd. and its suppliers and may be covered\n",
    "by UK and Foreign Patents, patents in process, and are protected by trade\n",
    "secret or copyright law. Dissemination of this information or\n",
    "reproduction of this material is strictly forbidden unless prior written\n",
    "permission is obtained from QuantumBlack Visual Analytics Ltd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive analytics\n",
    "\n",
    "Descriptive analytics is one of the most critical stages within any analytics project. Although projects can vary quite significantly, this phase typically lasts for ~3 weeks and should allow us to answer the following questions:  \n",
    "\n",
    "* Do I have all the data required to make actionable recommendations at the end of the project?\n",
    "* Are there any underlying issues with the data such as missing values or data inconsistencies?\n",
    "* What has happened in the past and why?\n",
    "* Does the data make business sense and align with previous results observed by the business?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "#### Importing packages\n",
    "Packages allow us to carry out more complex operations, here are some descriptions of what packages are used throughout this exercise:  \n",
    "\n",
    "* `os`    : provides a portable way of using operating system dependent functionality\n",
    "* `pandas`     : enables us to do data manipulation (on data.frames)\n",
    "* `numpy`    : to apply operations on data (processed as arrays and matrices)\n",
    "* `matplotlib` : enables us to interactively visualise and plot data\n",
    "* `seaborn`    : interacts well with matplotlib and gives diagrams which are more visually appealing\n",
    "* `sklearn`    : provides many machine learning algorithms\n",
    "* `scipy`    : enables us to use mathematical functions (e.g., Euclidian distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c3d0fef003bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mclust\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn.cluster as clust\n",
    "from scipy.spatial.distance import cdist\n",
    "%matplotlib inline\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the big picture of a dataset\n",
    "A few functions are particularly useful to get the holistic view of a dataset \n",
    "\n",
    "* `df.head()`: Print first n (default=5) rows of dataset\n",
    "* `df.info()`: Give overall information of dataset like column names, non-null row count and data type altogether\n",
    "* `df['categorical_column_name'].value_counts()`: Count distinct value (**For Categorical Columns**)\n",
    "* `df.describe()`: Basic statistics (count, max, min, quantiles) (**For Numerical Columns by default**) - you need to mention **df.describe(include='all')**, to include both numerical or categorical variables - look at the documentation for further information: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the 'data' folder\n",
    "df_raw = pd.read_csv(\"data/adults.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the feed data and scan through the structure\n",
    "\"\"\"\n",
    "Hint : You can use .head(x) to look at the top x rows of data\n",
    "\"\"\"\n",
    "df_raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A good way to get the bigger picture of the dataset is to use .info()\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive summary of numerical columns\n",
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive summary of numerical columns\n",
    "df_raw.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value counts for categorical columns\n",
    "df_raw['income'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value counts for categorical columns\n",
    "df_raw['occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Feel free to try more (for free).\n",
    "Uncomment the following lines.\n",
    "Shortcut to comment/uncomment is: CTRL (or cmd) + \"/\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# df_raw['occupation'].value_counts()\n",
    "# df_raw['workclass'].value_counts()\n",
    "# df_raw['education'].value_counts()\n",
    "# df_raw['marital-status'].value_counts()\n",
    "# df_raw['relationship'].value_counts()\n",
    "# df_raw['race'].value_counts()\n",
    "# df_raw['sex'].value_counts()\n",
    "# df_raw['native-country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect data quality\n",
    "1. Eye-ball if **data type** is correct\n",
    ">1. It is common that some columns are initially to the wrong data type \n",
    ">1. (e.g., data type for age can sometimes set to object instead of int, if there are any strange characters).\n",
    ">1. You can use `pd.to_numeric(df)` or `df.astype()` to change the data type accordingly.\n",
    "\n",
    "1. Numerical columns usually require some fixing (e.g., use commas for large values)\n",
    "> `df_raw[fix_cols] = df_raw[fix_cols] \\\n",
    "    .apply(lambda x : x.str.replace(\",\",\".\")) \\\n",
    "    .apply(pd.to_numeric)`\n",
    "\n",
    "1. Pay attention to missing (or null) values\n",
    "> 1. remove empty rows/columns `dropna()`\n",
    "> 1. impute empty values (often with median/mean values) `fillna()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify for which variables the \" ?\" is present and its frequency (%)\n",
    "col_names = df_raw.columns\n",
    "num_data = df_raw.shape[0]\n",
    "for c in col_names:\n",
    "    num_non = df_raw[c].isin([\" ?\"]).sum()\n",
    "    if num_non > 0:\n",
    "        print (c)\n",
    "        print (num_non)\n",
    "        print (\"{0:.2f}%\".format(float(num_non) / num_data * 100))\n",
    "        print (\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with '?'\n",
    "df_raw = df_raw[df_raw[\"workclass\"] != \" ?\"]\n",
    "df_raw = df_raw[df_raw[\"occupation\"] != \" ?\"]\n",
    "df_raw = df_raw[df_raw[\"native-country\"] != \" ?\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with categorical values\n",
    "Most models cannot handle categorical (`object`) values - you hence need to transform them, if you want to include them in your model before modelling. Two approaches are possible:\n",
    "\n",
    "1. **Label Encoding** (for interpretation)\n",
    "> Label encoding is simply converting each categorical value in a column to a number. \n",
    "> * **Advantage**: straightforward\n",
    "> * **Disadvantage**: the numeric values can be **“misinterpreted”** by the algorithms, as it enforces an order to values, which might not reflect the truth in your data - e.g., for occupation, can we say that one occupation is more valuable than another? (short answer: no).\n",
    "\n",
    "1. **One-hot Encoding** (for modelling)\n",
    "> One-hot encoding converts each categorical value into a new column and assigns a 1 or 0 (True/False) value to each row.\n",
    "> * **Advantage**: \"neutral\" representation of the data (does not assign an order)\n",
    "> * **Disadvantage**: can **significantly increase** the number of columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select numerical columns and categorical columns seprately\n",
    "int64_df = df_raw.select_dtypes(include=['int64'])\n",
    "# change object to category data type\n",
    "object_df = df_raw.select_dtypes(include=['object']).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view changed types\n",
    "object_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View summary of categorical columns\n",
    "# It indicates the top value (mode) and its associated frequency\n",
    "object_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL ENCODING\n",
    "# change 'income' to label encoding\n",
    "object_df[\"income_cat\"] = object_df[\"income\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View your transformed variable in the dataset\n",
    "object_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE-HOT ENCODED\n",
    "# With `pd.get_dummies`\n",
    "one_hot_df = pd.get_dummies(df_raw, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 columns in the initial dataset\n",
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding added 82 columns to the initial dataset!\n",
    "# Food for thought: why do you think this could be an issue?\n",
    "one_hot_df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise your dummy variables\n",
    "one_hot_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Our data is now in the correct format and we can do some descriptive analyses!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning data into insights\n",
    "Data visualisation is vital to obtain preliminary insights on the data before any modelling step. The following plots are commonly used:\n",
    "\n",
    "1. `histogram`\n",
    "> A histogram represents the distribution of numerical data. It is an estimate of the probability distribution of a continuous variable.\n",
    "\n",
    "1. `box plot`\n",
    "> The box plot (a.k.a. box and whisker diagram) is a standardized way to display the distribution of data based on the five following summary statistics: minimum, first quartile, median, third quartile, and maximum. It is a very useful plot to very quickly visualise the distribution of a continuous variable across multiple categories.\n",
    "\n",
    "1. `correlation plot`/`clustermap (using hierarchical clustering)`\n",
    "> A correlation matrix is a table showing Pearson correlation coefficients between selected variables. Each cell in the table shows the Pearson correlation between two variables. A clustermap is a correlation matrix to which hierarchical clustering has been applied.\n",
    "\n",
    "1. `scatter plot`\n",
    "> A scatterplot helps identify a linear relationship between two variables. A scatterplot can also be called a scattergram or a scatter diagram. It is another way to illustrate correlation between two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "df_raw.hist(bins=15, figsize=(20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Boxplot\n",
    "one_hot_df.boxplot(column=['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get correlation matrix\n",
    "corr = one_hot_df.corr().values\n",
    "# Set up the figure and its dimensions\n",
    "f, ax = plt.subplots(figsize=(30, 30))\n",
    "# Build correlation visualisation\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simpler and less saturated correlation matrix\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the figure and its dimensions\n",
    "f, ax = plt.subplots(figsize=(50, 30))\n",
    "\n",
    "# Generate a colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the correlation matrix with the colormap above\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build clustermap\n",
    "sns.clustermap(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Draw the correlation matrix with the customized colormap `cmap` defined above\n",
    "sns.clustermap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the pairplot of the whole dataset\n",
    "sns.pairplot(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... but how can i **explain** this scatter plot? You can reference the below plot to get the Pearson's correlation coefficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colour data points according to their income category\n",
    "sns.pairplot(df_raw, hue='income')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means clustering\n",
    "\n",
    "Visualising in 2d and 3d is simple, however dimensions greater than 3 can be difficult to visualise. K-means clustering is an **unsupervised learning approach** which aims to split the data into K distinct clusters by aggregating large numbers of features into condensed representations.  \n",
    "\n",
    "There are three main steps for `K-means clustering`:\n",
    "> * **Initialisation** – K points are randomly set as cluster centres (a.k.a., centroids or 'means')\n",
    "> * **Assignment** – K clusters are created by associating each observation to the nearest centroid\n",
    "> * **Update** – the position of each cluster's centroid is updated based on the new mean calculated\n",
    "\n",
    "One issue is that it gives an equal weight to all features used for clustering which inaccurate when the scale is different for all features. In order to rectify these inaccuracies, we generally scale our data by standardising it with the following formula: if we note $x$, as the original data point and $x_{std}$, as the standardised data point:\n",
    "\n",
    "\n",
    "$x_{std} = \\frac{x - {\\mu}}{\\sigma}$ where ${\\mu}$ is the mean of the feature and ${\\sigma}$ is the standard deviation of the feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Look at average values for our One-hot encoded data\n",
    "one_hot_df.apply(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise the One-hot encoded features\n",
    "std_features = (one_hot_df\n",
    "                .apply(lambda x : (x - np.mean(x)) / np.std(x)))\n",
    "std_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply K-means\n",
    "## Always set a random seed, to be able to reproduce results\n",
    "np.random.seed(2)\n",
    "std_features_sample = std_features\n",
    "\n",
    "avg_dist = []\n",
    "# You can try build more clusters, the current loop tries 1 cluster to 10\n",
    "K = range(1,10)\n",
    "for k in K:\n",
    "    # Select number of clusters to build\n",
    "    kmeanModel = clust.KMeans(n_clusters=k).fit(std_features_sample)\n",
    "    # Find total distance from closest cluster for each point \n",
    "    total_distance_sum = (np.min(cdist(std_features_sample, kmeanModel.cluster_centers_, 'euclidean'), axis=1))\n",
    "    # Find average distance for number of clusters\n",
    "    avg_dist.append(sum(total_distance_sum) / std_features_sample.shape[0])\n",
    "\n",
    "plt.plot(K, avg_dist, 'bx-')\n",
    "plt.grid()\n",
    "plt.xlabel('# of clusters')\n",
    "plt.ylabel('Average distance per cluster')\n",
    "plt.title('The Elbow Method showing the optimal # of clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average intra-cluster distance will almost always decrease as we create increasingly more clusters. Hypothetically we could build an equal amount of clusters to the number of data points and have an intra-cluster distance equal to 0. However, the marginal benefit of adding an additional cluster illustrates that these improvements also decline which result in the elbow-like shape. \n",
    "\n",
    "Based on the plot we can see that the plot *elbows* at around 5 clusters. We will choose 3 for now and evaluate the results in the next steps. One of the advantages of this algorithm is that it takes into account all features used in the algorithm with equal importance. \n",
    "\n",
    "This means that we do not need to visualise K dimensions any more and hand pick our boundaries.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply K-means - build models with 3 centres\n",
    "## Always set a random seed, to be able to reproduce results\n",
    "np.random.seed(2) # If you ran this in the previous cell, you do not need to run it again\n",
    "\n",
    "# We can this experiment with a varying number of clusters\n",
    "number_of_clusters = 3\n",
    "kmeanModel = clust.KMeans(n_clusters = number_of_clusters).fit(std_features_sample)\n",
    "\n",
    "# Select the sample we previously selected\n",
    "df_sample = one_hot_df.loc[std_features_sample.index]\n",
    "df_sample['cluster'] = np.argmin(cdist(std_features_sample, kmeanModel.cluster_centers_, 'euclidean'), axis = 1)\n",
    "\n",
    "df_sample.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at each cluster's average characteristics (will define centroid)\n",
    "df_sample.groupby('cluster').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at each cluster's size\n",
    "df_sample.cluster.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
